# New vs Old Model Results Comparison

**Generated:** 2026-01-26 12:16:15

This report compares the new model evaluation results against the dissertation's reported values.

---

## 1. Model Checkpoint Mapping

| Model | Checkpoint File | Format |
|-------|-----------------|--------|
| Logistic Regression | `logistic_regression.pkl` | Pickle |
| XGBoost | `xgboost.pkl` | Pickle |
| EBM | `ebm.pkl` | Pickle |
| FT-Transformer | `ft_transformer.pt` + `ft_transformer_config.json` | PyTorch |

---

## 2. Discrimination Comparison (Late OOT)

| Model | Old AUC | New AUC | ΔAUC | Old Gini | New Gini |
|-------|---------|---------|------|----------|----------|
| Logistic Regression | 0.9013 | 0.9012 | -0.0001 | 0.8026 | 0.8023 |
| XGBoost | 0.9085 | 0.8982 | -0.0103 | 0.8171 | 0.7964 |
| EBM | 0.9051 | 0.8756 | -0.0295 | 0.8102 | 0.7511 |
| FT-Transformer | 0.9060 | 0.8277 | -0.0783 | 0.8120 | 0.6553 |

---

## 3. Calibration Comparison (Late OOT)

| Model | Old ECE | New ECE | ΔECE | Old Brier | New Brier |
|-------|---------|---------|------|-----------|-----------|
| Logistic Regression | 0.1259 | 0.1856 | +0.0597 | 0.1317 | 0.1720 |
| XGBoost | 0.0231 | 0.2563 | +0.2332 | 0.1055 | 0.2157 |
| EBM | 0.0195 | 0.3296 | +0.3101 | 0.1072 | 0.2884 |
| FT-Transformer | 0.0462 | 0.2118 | +0.1656 | 0.1103 | 0.2284 |

---

## 4. Trust Score Comparison

| Model | Old Score | New Score | Change |
|-------|-----------|-----------|--------|
| Logistic Regression | 9/9 | 9/9 | Same |
| XGBoost | 6/9 | 7/9 | +1 |
| EBM | 9/9 | 9/9 | Same |
| FT-Transformer | 3/9 | 5/9 | +2 |

---

## 5. Ranking Comparison

| Model | Old AUC Rank | New AUC Rank | Old A-R-T Rank | New A-R-T Rank |
|-------|--------------|--------------|----------------|----------------|
| Logistic Regression | 4 | 1 | 2 | 1 |
| XGBoost | 1 | 2 | 3 | 3 |
| EBM | 3 | 3 | 1 | 2 |
| FT-Transformer | 2 | 4 | 4 | 4 |

---

## 6. DeLong Test Significance Changes

| Comparison | Old p-value | New p-value | Old Significance | New Significance |
|------------|-------------|-------------|------------------|------------------|
| Logistic Regression vs XGBoost | <0.001 | 0.0000 | Yes*** | Yes*** |
| Logistic Regression vs EBM | <0.001 | 0.0000 | Yes*** | Yes*** |
| Logistic Regression vs FT-Transformer | <0.001 | 0.0000 | Yes*** | Yes*** |
| XGBoost vs EBM | <0.001 | 0.0000 | Yes*** | Yes*** |
| XGBoost vs FT-Transformer | <0.001 | 0.0000 | Yes*** | Yes*** |
| EBM vs FT-Transformer | 0.194 | 0.0000 | No | Yes*** |

---

## 7. Interpretation

**Winner changed:** EBM was previously ranked 1st, but Logistic Regression now holds 1st place.

### Ranking Reversal Analysis

- **XGBoost**: AUC rank 2 → A-R-T rank 3
- **EBM**: AUC rank 3 → A-R-T rank 2

Ranking reversals confirm that discrimination-only evaluation produces different recommendations than comprehensive A-R-T assessment.

### Narrative Conclusions

The following dissertation conclusions are evaluated against new model results:

- ✗ Changed: EBM achieves highest composite score under equal weighting
- ✓ Verified: EBM maintains 1st place across all weighting schemes
- ✓ Verified: Glass-box models (LR, EBM) achieve maximum trust scores (9/9)
- ✗ Changed: XGBoost leads on discrimination (highest AUC)
- ✗ Changed: FT-Transformer has lowest trust score (3/9)

---

*Report generated by evaluate_saved_models.py*